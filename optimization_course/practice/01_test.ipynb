{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольная работа #1\n",
    "В этой контрольной работе разрешается пользоваться пакетом `cvxpy`, линейной алгеброй из `numpy/scipy`, но не `sklearn`.\n",
    "## Задача #1 (2б): проекция на линейное подпространство\n",
    "Дана невырожденная матрица $A\\in\\mathbb{R}^{m\\times n}$, $m<n$, вектор $b\\in \\mathbb{R}^{m}$ и точка $y\\in\\mathbb{R}^n$. Требуется найти точку $x$ такую, что $Ax=b$ и при этом $\\|x-y\\|$ принимает минильное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.linalg\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_subspace_projection(A, b, y):\n",
    "    \"\"\"\n",
    "    Возвращает точку x: Ax=b, ||x-y||->min\n",
    "    \n",
    "    Args:\n",
    "        A: ndarray(m, n)\n",
    "        b: ndarray(m, 1)\n",
    "        y: ndarray(n, 1)\n",
    "        \n",
    "    Returns:\n",
    "        x: ndarray(n, 1)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_projection():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "        \n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "        \n",
    "    A = np.random.rand(1, 2)\n",
    "    b = 0.5\n",
    "    \n",
    "    y = np.random.rand(2, 1)\n",
    "    \n",
    "    x = linear_subspace_projection(A, b, y)\n",
    "    ax.scatter([y[0], x[0]], [y[1], x[1]], color='black')\n",
    "    ax.plot([y[0], x[0]], [y[1], x[1]], color='grey', linestyle='--')\n",
    "    ax.text(x[0] - 0.1, x[1] - 0.1, 'x', fontsize = 15)\n",
    "    ax.text(y[0] + 0.1, y[1] + 0.1, 'y', fontsize = 15)\n",
    "    delta = 0.05\n",
    "    p = np.arange(-1.5, 1.5, delta)\n",
    "    q = np.arange(-1.5, 1.5, delta)\n",
    "    X, Y = np.meshgrid(p, q)\n",
    "    Z = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Z[i][j] = A @ np.array([X[i][j], Y[i][j]])\n",
    "    CS = ax.contour(X, Y, Z, [b], colors=['blue'])\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_projection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача #2 (4б): логистическая регрессия\n",
    "В этой задаче вам предлагается обучить модель линейной регрессии: дан набор точек $x_i\\in \\mathbb{R}^n$ и соответствующих им меток $y_i\\in \\{0, 1\\}$. Нужно найти гиперплоскость как можно лучше разделяющую точки с метками $0$ от точек с метками $1$. В логистической регрессии обучается модель-предиктор:\n",
    "$$\n",
    "f(x, \\theta)=\\sigma (\\theta^Tx)\n",
    "$$\n",
    "где\n",
    "$$\n",
    "\\sigma(t)=\\frac{1}{1+e^{-t}}.\n",
    "$$\n",
    "$\\theta$ соответствует параметрам гиперплоскости, вдоль которой идет разделение. Величина $f(x, \\theta)$ трактуется как вероятность принадлежности к классу с меткой $1$. Критерий максимального правдоподобия в данном случае эквивалентен минимизации кросс-энтропии\n",
    "$$\n",
    "\\mathcal{J}(x, y, \\theta)=-\\frac{1}{m}\\sum_{i=1}^m\\left[y_i\\log f(x_i, \\theta)+(1-y_i)(1-\\log(1-f(x_i, \\theta)))\\right]\n",
    "$$\n",
    "Стоит отметить, что\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\frac{d}{dt}\\sigma(t)&=\\left(\\frac{1}{1+e^{-t}}\\right)'\\\\\n",
    "&=-\\frac{-e^{-t}}{(1+e^{-t})^2}\\\\\n",
    "&=(1-\\sigma(t))\\sigma(t)\n",
    "\\end{array}\n",
    "$$\n",
    "и, соответственно\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\nabla_\\theta\\mathcal{J}(x, y, \\theta)&=-\\frac{1}{m}\\sum_{i=1}^m\\left[y_i\\frac{1}{\\sigma(\\theta^Tx_i)}(1-\\sigma(\\theta^Tx_i))\\sigma(\\theta^Tx_i)x_i-(1-y_i)\\frac{1}{1-\\sigma(\\theta^Tx_i)}(1-\\sigma(\\theta^Tx_i))\\sigma(\\theta^Tx_i)x_i\\right]\\\\\n",
    "&=-\\frac{1}{m}\\sum_{i=1}^m\\left[y_i(1-\\sigma(\\theta^Tx_i))x_i-(1-y_i)\\sigma(\\theta^Tx_i)x_i\\right]\\\\\n",
    "&=-\\frac{1}{m}\\sum_{i=1}^m\\left[(y_i-\\sigma(\\theta^Tx_i))x_i\\right]\n",
    "\\end{array}\n",
    "$$\n",
    "Реулизуйте обучение логистической регрессии с помощью градиентного спуска для смещенной логистической регрессии, т.е. для\n",
    "$$\n",
    "f(x, \\theta, \\beta)=\\sigma(\\theta^Tx+\\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x, y, alpha, iters):\n",
    "    \"\"\"\n",
    "    Возвращает оптимальные параметры логистической регрессии theta, beta, полученные минимизацией кросс-энтропии\n",
    "    \n",
    "    Args:\n",
    "        x: ndarray(m, n) -- матрица, каждая строка которой является точкой, которые отделяются регрессией\n",
    "        y: ndarray(m)    -- вектор-столбец, i-ый элемент которого соответствует метке i-ой строке в x,\n",
    "                            принимает значения 0 или 1\n",
    "        alpha: float -- размер шага для градиентного спуска\n",
    "        iters: int   -- количество итераций градиентного спуска\n",
    "    Returns:\n",
    "        theta: ndarray(n)\n",
    "        beta: float/ndarray(1) -- параметры регрессии\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[7, 7])\n",
    "n = 2\n",
    "m = 1000\n",
    "x = 2 * np.random.rand(m, n) - 1\n",
    "a = np.random.rand(n)\n",
    "b = 0.2\n",
    "\n",
    "y = (np.sign(x @ a + np.ones(m) * b) + 1) / 2\n",
    "\n",
    "theta, beta = logistic_regression(x, y, 0.05, 1000)\n",
    "\n",
    "ax.scatter(x[y > 0,0], x[y > 0,1], color='red')\n",
    "ax.scatter(x[y == 0,0], x[y == 0,1], color='blue')\n",
    "#Level contours\n",
    "delta = 0.025\n",
    "x_ = np.arange(-1, 1, delta)\n",
    "y_ = np.arange(-1, 1, delta)\n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = np.zeros_like(X)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        Z[i][j] = theta @ np.array([X[i][j], Y[i][j]]) + beta\n",
    "        \n",
    "CS = ax.contour(X, Y, Z, [0], colors=['black'])\n",
    "plt.close(fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача #3 (3б): линейное программирование\n",
    "В этой задаче вам предлагается решить задачу линейного программирования в стандартной форме\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mbox{минимизировать } &~ c^Tx\\\\\n",
    "\\mbox{при условии } &~ Ax\\leq b \\\\\n",
    "&~x\\geq 0\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_lp(A, b, c):\n",
    "    \"\"\"\n",
    "    Решает задачу линейного программирования\n",
    "    c^Tx->min\n",
    "    Ax<=b\n",
    "    x>=0\n",
    "    \n",
    "    args:\n",
    "        A: ndarray(m, n)\n",
    "        b: ndarray(m)\n",
    "        c: ndarray(n)\n",
    "        \n",
    "    returns:\n",
    "        x: ndarray(n)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from two points defines the coefficients a, b, c such that a line ax+by=c goes through these points \n",
    "def get_line(x1, x2):\n",
    "    a = x1[1] - x2[1]\n",
    "    b = x2[0] - x1[0]\n",
    "    c = a * x1[0] + b * x1[1]\n",
    "    return a, b, c\n",
    "\n",
    "vertices = [(2.0, 2.0), (1.9, 3.0), (2.5, 4.0), (4.0, 4.2), (4.7, 3.5), (4.5, 1.5), (3.5, 1.0), (2.0, 2.0)]\n",
    "A = []\n",
    "b = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "for i in range(len(vertices) - 1):\n",
    "    a_, b_, c_ = get_line(vertices[i], vertices[i + 1])\n",
    "    A.append([a_, b_])\n",
    "    b.append(c_)\n",
    "    #print(f'{float(a):6.2} * x + {float(b):4.2} * y <= {float(a):4.2}')\n",
    "A = np.array(A)\n",
    "b = np.array(b)\n",
    "direction = np.array([-2, -1]) # c\n",
    "x = solve_lp(A, b, direction)\n",
    "ax.plot([x for x, y in vertices], [y for x, y in vertices])\n",
    "ax.scatter([x[0]], [x[1]], color='black')\n",
    "ax.arrow(x[0], x[1], direction[0] * 0.3, direction[1] * 0.3, head_width=0.07, overhang=0.5)\n",
    "ax.text(x[0] + direction[0] * 0.15 - 0.1, x[1] + direction[0] * 0.15 + 0.2, '$c$', fontsize=20)\n",
    "ax.text(x[0] - 0.05, x[1] + 0.1, '$x^*$', fontsize=20)\n",
    "\n",
    "plt.close(fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача #4 (3б): минимум максимума нескольких линейных функций\n",
    "Дан набор одномерных линейных функций, требуется найти точку минимума максимума этих функций\n",
    "$$\n",
    "\\max_{1\\leq i\\leq m}a_ix+b_i\\rightarrow \\min\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(a, b):\n",
    "    \"\"\"\n",
    "    max a_ix+b_i -> min\n",
    "    \n",
    "    args:\n",
    "        a: ndarray(m)\n",
    "        b: ndarray(m)\n",
    "        \n",
    "    returns:\n",
    "        x: ndarray(m)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "a = np.random.rand(m) * 2 - 1\n",
    "b = 5 * (np.random.rand(m) * 2 - 1)\n",
    "\n",
    "q = np.arange(-10, 10, 0.01)\n",
    "\n",
    "f = lambda x: max([a[i] * x + b[i] for i in range(a.shape[0])])\n",
    "\n",
    "x = min_max(a, b)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.plot(q, [f(x) for x in q])\n",
    "ax.scatter([x], [f(x)], color='black')\n",
    "plt.close(fig)\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
